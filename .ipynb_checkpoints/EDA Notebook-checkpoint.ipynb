{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTENTION!\n",
    "\n",
    "## Ask yourself the following questions before moving forward. \n",
    " -  ### Have I thought about the client's problem and their objectives?\n",
    " -  ### Have I researched the domain space and/or similar projects?\n",
    " -  ### Have I gained a birds-eye view of the data - scope, time frames, etc?\n",
    " \n",
    "\n",
    "## If you answer yes to all 3 (ideally) then it's time for EDA!\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%% get libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 300\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "import matplotlib.pyplot as plt ###\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "import missingno as msno\n",
    "from eda.discover import discover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% get data and peek\n",
    "train = pd.read_csv('./input/raw/application_train.csv', index_col='SK_ID_CURR')\n",
    "test = pd.read_csv('./input/raw/application_test.csv', index_col='SK_ID_CURR')\n",
    "test['TARGET'] = 2\n",
    "print (train.shape, '\\n', \n",
    "       train.TARGET.sum(), '\\n',\n",
    "       test.shape)\n",
    "\n",
    "traintest = pd.concat([train, test], sort=False).sort_index()\n",
    "traintest.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traintest.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% for demo only: reduce features...\n",
    "keepers = ['TARGET', 'AMT_INCOME_TOTAL',\n",
    " 'AMT_CREDIT', 'AMT_ANNUITY',\n",
    " 'AMT_GOODS_PRICE', 'NAME_EDUCATION_TYPE',\n",
    " 'NAME_FAMILY_STATUS', 'REGION_POPULATION_RELATIVE',\n",
    " 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
    " 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH',\n",
    " 'OWN_CAR_AGE', 'OCCUPATION_TYPE',\n",
    " 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START',\n",
    " 'ORGANIZATION_TYPE', 'EXT_SOURCE_1',\n",
    " 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    " 'BASEMENTAREA_AVG', 'YEARS_BUILD_AVG',\n",
    " 'LANDAREA_AVG', 'BASEMENTAREA_MODE', 'CODE_GENDER',\n",
    " 'TOTALAREA_MODE', 'DAYS_LAST_PHONE_CHANGE',\n",
    " 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n",
    "\n",
    "trainlite = train[keepers]\n",
    "traintestlite = traintest[trainlite.columns]\n",
    "ttsamp = traintestlite.reset_index().sample(frac = 0.1).sort_index()\n",
    "ttsamp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%% get automated description of combined dataset\n",
    "ProfileReport(traintestlite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve [height=200 width=500]\n",
    "\n",
    "#check for patterns by id order\n",
    "curve1 = hv.Curve(ttsamp, 'SK_ID_CURR','SK_ID_CURR')\n",
    "curve2 = hv.Curve(ttsamp, 'SK_ID_CURR','AMT_CREDIT')\n",
    "curve3 = hv.Curve(ttsamp[ttsamp.TARGET < 2], 'SK_ID_CURR','TARGET')\n",
    "\n",
    "patterns = (curve1 + curve2 + curve3).cols(1)\n",
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% check duplicate rows and constant columns\n",
    "duperows = ttsamp.drop('TARGET', axis=1).duplicated(keep=False).sum()\n",
    "consts = ttsamp.nunique(axis=0)\n",
    "print(duperows, '\\n', consts[consts == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%% check scatters with pandas\n",
    "# pd.plotting.scatter_matrix(ttsamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Scatter [tools=['box_select'] border=0] Histogram {+axiswise}\n",
    "%%output size=150\n",
    "\n",
    "#check scatters\n",
    "table = hv.Table(ttsamp.iloc[:, 2:6])\n",
    "matrix = hv.operation.gridmatrix(table)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Distribution  [height=240 width=240]\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", FutureWarning)\n",
    "\n",
    "#%% check distros for numericals\n",
    "allnums = ttsamp.drop('TARGET', axis = 1).select_dtypes(include='float')\n",
    "plot_list = [hv.Distribution(train[c])*hv.Distribution(test[c]) for c in allnums.columns]\n",
    "pltmat = hv.Layout(plot_list)\n",
    "pltmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find outliers in train and test\n",
    "# code borrowed from Kaggle kernels\n",
    "\n",
    "\n",
    "\n",
    "def rand_jitter(arr):\n",
    "    return arr + np.random.randn(len(arr))\n",
    "\n",
    "def draw_feature_distribution(df, column):\n",
    "    column_values = df[df[column].notna()][column]\n",
    "    # group by target\n",
    "    class_0_values = df[df[column].notna() & (df['TARGET']==0)][column]\n",
    "    class_1_values = df[df[column].notna() & (df['TARGET']==1)][column]\n",
    "    class_t_values = df[df[column].notna() & (df['TARGET']==2)][column]        \n",
    "    print('\\n\\n', column)\n",
    "    # for features with unique values >= 10\n",
    "    if len(df[column].value_counts().keys()) >= 10:\n",
    "        fig, ax = plt.subplots(1, figsize=(15, 4))\n",
    "        if df[column].dtype == 'object':\n",
    "            label_encoder = LabelEncoder()\n",
    "            label_encoder.fit(column_values)\n",
    "            class_0_values = label_encoder.transform(class_0_values)\n",
    "            class_1_values = label_encoder.transform(class_1_values)\n",
    "            class_t_values = label_encoder.transform(class_t_values)\n",
    "            column_values = label_encoder.transform(column_values)\n",
    "            plt.xticks(range(len(label_encoder.classes_)), label_encoder.classes_, fontsize=12, rotation='vertical')\n",
    "\n",
    "        ax.scatter(class_0_values, rand_jitter([0]*class_0_values.shape[0]), label='Class0', s=10, marker='o', color='#7ac143', alpha=1)\n",
    "        ax.scatter(class_1_values, rand_jitter([10]*class_1_values.shape[0]), label='Class1', s=10, marker='o', color='#fd5c63', alpha=1)\n",
    "        ax.scatter(class_t_values, rand_jitter([20]*class_t_values.shape[0]), label='Test', s=10, marker='o', color='#037ef3', alpha=0.4)\n",
    "        ax.set_title(column +' group by target', fontsize=16)\n",
    "        ax.legend(bbox_to_anchor=(1.01, 1), loc=\"upper left\")\n",
    "        ax.set_title(column +' distribution', fontsize=16)\n",
    "      \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "show_feature_count = 10\n",
    "for column in ttsamp.columns:\n",
    "    if show_feature_count == 0:\n",
    "        break\n",
    "    show_feature_count -= 1\n",
    "    draw_feature_distribution(ttsamp, column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% check cat columns differences\n",
    "allobjs = traintest.select_dtypes(include='object')\n",
    "for c in allobjs.columns:\n",
    "    s1 = set(train[c].unique())\n",
    "    s2 = set(test[c].unique())\n",
    "    diff = s1.symmetric_difference(s2)\n",
    "    for d in diff:\n",
    "        tnrows = train[train[c] == d].shape[0]\n",
    "        tsrows = test[test[c] == d].shape[0]\n",
    "        print('{}, \"{}\": {} in train, {} in test'.format(c,d,tnrows, tsrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%Look at feature ratios by target value:\n",
    "def catcompare(feature):\n",
    "    h = train[feature].value_counts(normalize=True)\n",
    "    i = test[feature].value_counts(normalize=True)\n",
    "    catlist = h.index.tolist() + i.index.tolist()\n",
    "    pctlist = h.tolist() + i.tolist()\n",
    "    setlist = ['train']*h.shape[0] + ['test']*i.shape[0]\n",
    "    macro = hv.Table((catlist, setlist, pctlist), ['cat', 'set'], ['pct'])\n",
    "    plot = macro.to.bars(kdims=['cat', 'set'], vdims='pct', groupby=[], label = feature)\n",
    "    return plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Bars.Grouped [group_index='set']\n",
    "%%opts Bars [group_index=1 xrotation=45 width=480 show_legend=False tools=['hover']] \n",
    "%%opts Bars (color=Cycle('Paired')) \n",
    "\n",
    "allcats = traintest.drop('TARGET', axis = 1).select_dtypes(include='object') \n",
    "plot_list = [] \n",
    "for c in allcats.columns: \n",
    "    plot = catcompare(c) \n",
    "    plot_list.append(plot)\n",
    "hv.Layout(plot_list).cols(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% check missing variable structure\n",
    "msno.matrix(traintest, filter=None, n=0, p=0, sort=None,\n",
    "           figsize=(25, 15), width_ratios=(15, 1), color=(0.4, 0.7, 0.95),\n",
    "           fontsize=8, labels=None, sparkline=False, inline=True, freq=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
